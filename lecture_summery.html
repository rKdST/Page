<!DOCTYPE html>
<html>
<title>Lecture Summery</title>
<body>

<style>
body {
  background-image: url('bg2.jpg');
  background-repeat: no-repeat;
  background-size: cover;
  margin:250px;
}
</style>

<h1 style="font-family:Garamond"><center>Lecture Summery</center></h1>
<h2 style="font-family:Garamond"><center>Topic: Designing Macromolecules using Machine Learning and Simulations</center></h2>
<h3 style="font-family:Garamond"><center>Presented by: Somesh Mohapatra</center></h3>
</center>
</body>
<body style="font-size:24px; font-family:Ttf">
<p>&nbsp;&nbsp;Macromolecules are complex structures made up of monomers and linkages that connect individual monomers into various topologies. They are important for gene therapy, delivery, and the development of destructible thermostats. For the computation of macromolecules researchers initially approached using property vectors to represent macromolecules but faced challenges in customization when changing the type of atoms or monomers which resulted in new representations every time the chemical space changed. Machine learning methods such as ChemProp and neural networks are being used to discover, predict, and optimize properties of molecules. However, there is still a limitation in representation or descriptors for macromolecules. In the nonlinear space, researchers were able to compare linear macromolecules to a variety of shapes, leading to the development of generalized similarity computation methods for two arbitrary macromolecules of known monomer composition and topology.</p>
<p>&nbsp;&nbsp;For Mr. Somesh Mohapatra’s approach, a dataset of 600 modular mini proteins was created. The students at Brad’s lab mapped each sequence to phenotyping readouts. The mean fluorescence intensity for each sequence was assigned to it on a scale of one to 20, indicating the maximum of the range of the training data set. The researchers used a generator predictor optimizer framework to design optimal many proteins, which was trained on a fingerprint matrix representation of the activity</p>
<p>&nbsp;&nbsp;The model was trained to generate new peptides and predict sequences with activity as high as 50 in some cases. The decision-making process of the model was influenced by attribution analysis and data augmentation.  The dataset had a mean length of around 42 amino acids, making it nearly impossible to design a design space with less than 20 amino acids. To address this challenge, the model was trained on a bimodal distribution, showing multiple times of shorter peptides and an equal amount of longer peptides that were more active in general.</p>
<p>&nbsp;&nbsp;The study then moved on to artificial macromolecules based on D constructible thermo sets. The model was trained on a dataset of 100 data points to understand the comonomer and crosslinker mole percentages. The model was able to predict the Glass Transition Temperature (TG-temperature at which a polymer changes from a rigid, brittle, glass-like state to a flexible, rubbery, viscous state.) reliably based on its own basis and found features that helped it make the decision of predicting Glass Transition Temperature reliably.</p>
<p>&nbsp;&nbsp;In summary, machine learning has revolutionized the way we understand and analyse macromolecules. With advances in representation, similarity computation, and modelling techniques, machine learning has become a powerful tool for discovering, predicting, and optimizing the properties of small molecules. By focusing on three key aspects: data type, data set size, and task, machine learning has provided valuable insights into the properties and interactions of various molecules.</p>
<p><center></center></p>

</body>
</html>